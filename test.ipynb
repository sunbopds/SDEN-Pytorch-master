{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from data_utils import *\n",
    "from model import SDEN\n",
    "import pickle\n",
    "import json\n",
    "import random\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = torch.load('weight/model.pkl',map_location=lambda storage, loc: storage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = checkpoint['config']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SDEN(len(checkpoint['vocab']),config.embed_size,config.hidden_size,\n",
    "             len(checkpoint['slot_vocab']),len(checkpoint['intent_vocab']))\n",
    "model.load_state_dict(checkpoint['model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SDEN(\n",
       "  (embed): Embedding(1179, 100, padding_idx=0)\n",
       "  (bigru_m): GRU(100, 64, batch_first=True, bidirectional=True)\n",
       "  (bigru_c): GRU(100, 64, batch_first=True, bidirectional=True)\n",
       "  (context_encoder): Sequential(\n",
       "    (0): Linear(in_features=256, out_features=128, bias=True)\n",
       "    (1): Sigmoid()\n",
       "  )\n",
       "  (session_encoder): GRU(128, 128, batch_first=True, bidirectional=True)\n",
       "  (decoder_1): GRU(100, 128, batch_first=True, bidirectional=True)\n",
       "  (decoder_2): LSTM(256, 128, batch_first=True, bidirectional=True)\n",
       "  (intent_linear): Linear(in_features=256, out_features=4, bias=True)\n",
       "  (slot_linear): Linear(in_features=256, out_features=24, bias=True)\n",
       "  (dropout): Dropout(p=0.3)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = json.load(open('../dataset/kvret/kvret_test_public.json','r'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = random.choice(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2intent = {v:k for k,v in checkpoint['intent_vocab'].items()}\n",
    "index2slot = {v:k for k,v in checkpoint['slot_vocab'].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = random.sample(data,2)\n",
    "index = random.choice([i for i in range(len(test[0]['dialogue'])) if i%2==0])\n",
    "test = test[0]['dialogue'][:index] + test[1]['dialogue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What', 'is', 'the', 'date', 'and', 'time', 'of', 'my', 'next', 'meeting', 'and', 'who', 'will', 'be', 'attending', 'it', '?']\n",
      "intent :  schedule\n",
      "slot :  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-event', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n",
      "['Please', 'give', 'me', 'the', 'address', 'and', 'directions', 'via', 'a', 'route', 'with', 'no', 'traffic', 'to', 'the', 'nearest', 'pizza', 'restaurant', '.']\n",
      "intent :  navigate\n",
      "slot :  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'B-traffic_info', 'O', 'O', 'B-distance', 'B-poi_type', 'I-poi_type', 'O']\n",
      "\n",
      "['Yes', ',', 'let', \"'s\", 'go', ',', 'thank', 'you', '!']\n",
      "intent :  thanks\n",
      "slot :  ['O', 'O', 'O', 'O', 'O', 'O', 'O', 'O', 'O']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "history=[[\"<null>\"]]\n",
    "for d in test:\n",
    "    utter = d['data']['utterance']\n",
    "    token = nltk.word_tokenize(utter)\n",
    "    c = prepare_sequence(token,checkpoint['vocab']).unsqueeze(0)\n",
    "    h = pad_to_history(history,checkpoint['vocab'])\n",
    "    with torch.no_grad():\n",
    "        s,i = model(h,c)\n",
    "    slot_p = s.max(1)[1]\n",
    "    intent_p = i.max(1)[1]\n",
    "    if d['turn']=='driver':\n",
    "        print(token)\n",
    "        print('intent : ',index2intent[intent_p.item()])\n",
    "        print('slot : ',[index2slot[s] for s in slot_p.data.tolist()])\n",
    "        print(\"\")\n",
    "    history.append(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
